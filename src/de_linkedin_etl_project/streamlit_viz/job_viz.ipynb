{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06645f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import snowflake.connector\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aeef990",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "rapidapi_key = os.getenv('RAPIDAPI_KEY')\n",
    "rapidapi_host = \"linkedin-job-search-api.p.rapidapi.com\"\n",
    "snowflake_password = os.getenv('SNOWFLAKE_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf43f0",
   "metadata": {},
   "source": [
    "## Snowflake Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af4e7327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Snowflake established successfully.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Snowflake\n",
    "#Establish a connection to Snowflake\n",
    "\n",
    "def connect_to_snowflake():\n",
    "    try:\n",
    "\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=\"NIKKILW2025\",\n",
    "            password=snowflake_password,\n",
    "            account=\"gbszkwp-by30611\",\n",
    "            warehouse=\"SNOWFLAKE_LEARNING_WH\",\n",
    "            database=\"linkedin_db\",\n",
    "            schema=\"linkedin_raw\"\n",
    "        )\n",
    "        print(\"Connection to Snowflake established successfully.\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Snowflake: {e}\")\n",
    "        return None\n",
    "\n",
    "conn = connect_to_snowflake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8790356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_job_total(conn):\n",
    "    query = \"\"\"\n",
    "        SELECT JOB_CATEGORY as Title,\n",
    "        COUNT(DISTINCT ID) as Total_Jobs\n",
    "        FROM LINKEDIN_JOB_API_CLEANED_DATA\n",
    "        WHERE\n",
    "        lower(title) LIKE '%data engineer%'\n",
    "        or lower(title) LIKE '%data analyst%'\n",
    "        or lower(title) LIKE '%data scientist%'\n",
    "        GROUP BY JOB_CATEGORY\n",
    "        ORDER BY Title ASC\n",
    "    \"\"\"\n",
    "    df_job_total = pd.read_sql(query, conn)\n",
    "    return df_job_total\n",
    "\n",
    "df_job_total = query_job_total(conn)\n",
    "df_job_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def job_data_summary(df_job_total):\n",
    "#     \"\"\"\n",
    "#     3 Summary Numbers of Total Jobs by Title\n",
    "#     \"\"\"\n",
    "#     col1, col2, col3 = st.columns(3)\n",
    "\n",
    "#     col1.metric(label='Data Analyst', value=int(df_job_total.iloc[0,1]))\n",
    "#     col2.metric(label='Data Engineer', value=int(df_job_total.iloc[1,1]))\n",
    "#     col3.metric(label='Data Scientist', value=int(df_job_total.iloc[2,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61c47960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15211/4181880399.py:16: UserWarning:\n",
      "\n",
      "pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TOTAL_JOBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-21</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE         TITLE  TOTAL_JOBS\n",
       "0  2025-04-21  Data Analyst           3\n",
       "1  2025-04-22  Data Analyst          13\n",
       "2  2025-04-23  Data Analyst          11\n",
       "3  2025-04-24  Data Analyst          10\n",
       "4  2025-04-25  Data Analyst           3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Get Daily jobs trend by title\n",
    "def query_daily_job_data(conn):\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "        DATE,\n",
    "        JOB_CATEGORY as Title,\n",
    "        SUM(TOTAL_JOBS) as Total_Jobs\n",
    "        FROM MART_TOTAL_JOBS_DAILY\n",
    "        WHERE\n",
    "        lower(title) LIKE '%data engineer%'\n",
    "        or lower(title) LIKE '%data analyst%'\n",
    "        or lower(title) LIKE '%data scientist%'\n",
    "        GROUP BY Title, DATE\n",
    "        ORDER BY Title, DATE ASC\n",
    "    \"\"\"\n",
    "    df_daily_jobs = pd.read_sql(query, conn)\n",
    "    return df_daily_jobs\n",
    "\n",
    "df_daily_jobs = query_daily_job_data(conn)\n",
    "df_daily_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import plotly_express as px\n",
    "\n",
    "def viz_daily_job_data(df_daily_jobs):\n",
    "    fig = px.line(df_daily_jobs, x='DATE', y='TOTAL_JOBS', color='TITLE',\n",
    "                  title='Data Job Daily Trend')\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "viz_daily_job_data(df_daily_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34755713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import nbformat\n",
    "print(nbformat.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def viz_daily_job_data(df_daily_jobs):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.lineplot(data=df_daily_jobs, x='DATE', y='TOTAL_JOBS', hue='TITLE')\n",
    "    plt.title('Data Job Daily Trend')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Total Jobs')\n",
    "    plt.legend(title='Job Title')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "viz_daily_job_data(df_daily_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa5389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e07ecc",
   "metadata": {},
   "source": [
    "## Section  - Dashboard Title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29662c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10361/126395210.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(city_query_base, conn)\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n         ELECT DISTINCT JOB_CATEGORY AS Job_Role,\n        ID, TITLE, EMPLOYMENT_TYPE, SENIORITY, CITY, STATE, ORGANIZATION,\n        URL AS LinkedIn_Post_Link, JOB_DATE AS Job_Posted_Date,\n        REMOTE_DERIVED AS IS_REMOTE,\n        LINKEDIN_ORG_URL,\n        LINKEDIN_ORG_INDUSTRY,\n        LINKEDIN_ORG_RECRUITMENT_AGENCY_DERIVED AS Job_By_Agency,\n        DIRECTAPPLY\n        FROM INT_LINKEDIN_DATA\n        ORDER BY JOB_DATE, JOB_CATEGORY\n                            ': 001003 (42000): SQL compilation error:\nsyntax error line 1 at position 0 unexpected 'ELECT'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2675\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/snowflake/connector/cursor.py:1134\u001b[39m, in \u001b[36mSnowflakeCursor.execute\u001b[39m\u001b[34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _force_qmark_paramstyle, _dataframe_ast)\u001b[39m\n\u001b[32m   1133\u001b[39m     error_class = IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[32m-> \u001b[39m\u001b[32m1134\u001b[39m     \u001b[43mError\u001b[49m\u001b[43m.\u001b[49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/snowflake/connector/errors.py:279\u001b[39m, in \u001b[36mError.errorhandler_wrapper\u001b[39m\u001b[34m(connection, cursor, error_class, error_value)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[32m    264\u001b[39m \n\u001b[32m    265\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m \u001b[33;03m    exception to the first handler in that order.\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m handed_over = \u001b[43mError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/snowflake/connector/errors.py:334\u001b[39m, in \u001b[36mError.hand_to_other_handler\u001b[39m\u001b[34m(connection, cursor, error_class, error_value)\u001b[39m\n\u001b[32m    333\u001b[39m cursor.messages.append((error_class, error_value))\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/snowflake/connector/errors.py:210\u001b[39m, in \u001b[36mError.default_errorhandler\u001b[39m\u001b[34m(connection, cursor, error_class, error_value)\u001b[39m\n\u001b[32m    209\u001b[39m done_format_msg = error_value.get(\u001b[33m\"\u001b[39m\u001b[33mdone_format_msg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[32m    211\u001b[39m     msg=error_value.get(\u001b[33m\"\u001b[39m\u001b[33mmsg\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    212\u001b[39m     errno=\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[32m    213\u001b[39m     sqlstate=error_value.get(\u001b[33m\"\u001b[39m\u001b[33msqlstate\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    214\u001b[39m     sfqid=error_value.get(\u001b[33m\"\u001b[39m\u001b[33msfqid\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    215\u001b[39m     query=error_value.get(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    216\u001b[39m     done_format_msg=(\n\u001b[32m    217\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[32m    218\u001b[39m     ),\n\u001b[32m    219\u001b[39m     connection=connection,\n\u001b[32m    220\u001b[39m     cursor=cursor,\n\u001b[32m    221\u001b[39m )\n",
      "\u001b[31mProgrammingError\u001b[39m: 001003 (42000): SQL compilation error:\nsyntax error line 1 at position 0 unexpected 'ELECT'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m     conn.close()\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m df = \u001b[43mjob_dates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mjob_dates\u001b[39m\u001b[34m(conn)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjob_dates\u001b[39m(conn):\n\u001b[32m      4\u001b[39m     city_query_base = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m         ELECT DISTINCT JOB_CATEGORY AS Job_Role,\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m        ID, TITLE, EMPLOYMENT_TYPE, SENIORITY, CITY, STATE, ORGANIZATION,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33m        ORDER BY JOB_DATE, JOB_CATEGORY\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m                            \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity_query_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     conn.close()\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/pandas/io/sql.py:706\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         _is_table_name = pandas_sql.has_table(sql)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2727\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2728\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2729\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2736\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2737\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2738\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2739\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/nikki099/de_linkedin_etl_project/.venv/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2683\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2685\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2686\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\n         ELECT DISTINCT JOB_CATEGORY AS Job_Role,\n        ID, TITLE, EMPLOYMENT_TYPE, SENIORITY, CITY, STATE, ORGANIZATION,\n        URL AS LinkedIn_Post_Link, JOB_DATE AS Job_Posted_Date,\n        REMOTE_DERIVED AS IS_REMOTE,\n        LINKEDIN_ORG_URL,\n        LINKEDIN_ORG_INDUSTRY,\n        LINKEDIN_ORG_RECRUITMENT_AGENCY_DERIVED AS Job_By_Agency,\n        DIRECTAPPLY\n        FROM INT_LINKEDIN_DATA\n        ORDER BY JOB_DATE, JOB_CATEGORY\n                            ': 001003 (42000): SQL compilation error:\nsyntax error line 1 at position 0 unexpected 'ELECT'."
     ]
    }
   ],
   "source": [
    "#query the min and max dates for dashboard subheading\n",
    "\n",
    "def job_dates(conn):\n",
    "    city_query_base = \"\"\"\n",
    "        SELECT DISTINCT JOB_CATEGORY AS Job_Role,\n",
    "        ID, TITLE, EMPLOYMENT_TYPE, SENIORITY, CITY, STATE, ORGANIZATION,\n",
    "        URL AS LinkedIn_Post_Link, JOB_DATE AS Job_Posted_Date,\n",
    "        REMOTE_DERIVED AS IS_REMOTE,\n",
    "        LINKEDIN_ORG_URL,\n",
    "        LINKEDIN_ORG_INDUSTRY,\n",
    "        LINKEDIN_ORG_RECRUITMENT_AGENCY_DERIVED AS Job_By_Agency,\n",
    "        DIRECTAPPLY\n",
    "        FROM INT_LINKEDIN_DATA\n",
    "        ORDER BY JOB_DATE, JOB_CATEGORY\n",
    "                            \"\"\"\n",
    "\n",
    "    df = pd.read_sql(city_query_base, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "df = job_dates(conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"Australia Data Job Trend Dashboard\")\n",
    "# st.subheader(f\"data date range {df_dates['MIN_DATE']} - {df_dates['MAX_DATE']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1f593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def viz_wow_trend():\n",
    "    today = datetime.now()\n",
    "    current_week = today - timedelta(days=today.weekday())\n",
    "    current_week = pd.to_datetime(current_week).date()\n",
    "    print(current_week)\n",
    "\n",
    "\n",
    "current_week = viz_wow_trend()\n",
    "current_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c9c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fb4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0eaf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc4ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d5fe4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c35a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c617e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f966da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7134780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16000a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
